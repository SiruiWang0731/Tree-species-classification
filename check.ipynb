{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebe9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# import the libraries you need\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.image import imread\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "from itertools import chain\n",
    "import json\n",
    "from jsonpath import jsonpath \n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "import tensorflow as tf\n",
    "# Folium setup.\n",
    "import folium\n",
    "\n",
    "\n",
    "# var DE_Forest =Picea_abies.merge(Fagus_sylvatica).merge(Pinus_sylvestris).merge(Quercus_robur).merge(Betula_pendula)\n",
    "# .merge(Quercus_petraea).merge(Fraxinus_excelsior).merge(Acer_pseudoplatanus).merge(Sorbus_aucuparia).merge(Carpinus_betulus)\n",
    "# .merge(Larix_decidua).merge(Abies_alba).merge(Pseudotsuga_menziesii).merge(Frangula_alnus).merge(Alnus_glutinosa)\n",
    "# .merge(Prunus_avium).merge(Populus_tremula).merge(Larix_kaempferi).merge(Quercus_rubra).merge(Acer_campestre)\n",
    "\n",
    "# In[3]:\n",
    "def navie_sample(src_image, label):\n",
    "        # forest-1, debris-2, water-3\n",
    "        classes = label\n",
    "        # get the feature space from drone image\n",
    "        #with rasterio.open(src_image) as src_ds:\n",
    "        #    src = src_ds.read()\n",
    "        \n",
    "        yield (src_image, label)\n",
    "geojson = '/home/manap/Documents/Data0129_needlebraod/GeoJson'\n",
    "root = '/home/manap/Documents/Data0129_needlebraod/npy'\n",
    "geosjons = os.listdir(geojson)\n",
    "index = 0\n",
    "index_tree_type = {}\n",
    "for file in geosjons:\n",
    "    path = os.path.join(geojson, file)\n",
    "    print(path)\n",
    "\n",
    "    tree_type = file.split('_')[0] + '_' + file.split('_')[1]\n",
    "    index_tree_type[index] = tree_type\n",
    "    kernel=9\n",
    "    bands=40\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    B8 = jsonpath(data, \"$..B8\")\n",
    "    print(type(B8))\n",
    "    print(len(B8))\n",
    "    print(len(B8[0]))\n",
    "\n",
    "\n",
    "    B8data=np.array(B8[0])\n",
    "    print(B8data.shape)\n",
    "    # plt.imshow(B8data) \n",
    "    #print(ddate) \n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "\n",
    "    B2 = jsonpath(data, \"$..B2\") \n",
    "    B3 = jsonpath(data, \"$..B3\") \n",
    "    B4 = jsonpath(data, \"$..B4\") \n",
    "    B5 = jsonpath(data, \"$..B5\") \n",
    "    B6 = jsonpath(data, \"$..B6\") \n",
    "    B7 = jsonpath(data, \"$..B7\") \n",
    "    B8 = jsonpath(data, \"$..B8\") \n",
    "    B8A = jsonpath(data, \"$..B8A\") \n",
    "    B11 = jsonpath(data, \"$..B11\") \n",
    "    B12 = jsonpath(data, \"$..B12\") \n",
    "    B2_1 = jsonpath(data, \"$..B2_1\") \n",
    "    B3_1 = jsonpath(data, \"$..B3_1\") \n",
    "    B4_1 = jsonpath(data, \"$..B4_1\") \n",
    "    B5_1 = jsonpath(data, \"$..B5_1\") \n",
    "    B6_1 = jsonpath(data, \"$..B6_1\") \n",
    "    B7_1 = jsonpath(data, \"$..B7_1\") \n",
    "    B8_1 = jsonpath(data, \"$..B8_1\") \n",
    "    B8A_1 = jsonpath(data, \"$..B8A_1\") \n",
    "    B11_1 = jsonpath(data, \"$..B11_1\") \n",
    "    B12_1 = jsonpath(data, \"$..B12_1\") \n",
    "    B2_2 = jsonpath(data, \"$..B2_2\") \n",
    "    B3_2 = jsonpath(data, \"$..B3_2\") \n",
    "    B4_2 = jsonpath(data, \"$..B4_2\") \n",
    "    B5_2 = jsonpath(data, \"$..B5_2\") \n",
    "    B6_2 = jsonpath(data, \"$..B6_2\") \n",
    "    B7_2 = jsonpath(data, \"$..B7_2\") \n",
    "    B8_2 = jsonpath(data, \"$..B8_2\") \n",
    "    B8A_2 = jsonpath(data, \"$..B8A_2\") \n",
    "    B11_2 = jsonpath(data, \"$..B11_2\") \n",
    "    B12_2 = jsonpath(data, \"$..B12_2\") \n",
    "    B2_3 = jsonpath(data, \"$..B2_3\") \n",
    "    B3_3 = jsonpath(data, \"$..B3_3\") \n",
    "    B4_3 = jsonpath(data, \"$..B4_3\") \n",
    "    B5_3 = jsonpath(data, \"$..B5_3\") \n",
    "    B6_3 = jsonpath(data, \"$..B6_3\") \n",
    "    B7_3 = jsonpath(data, \"$..B7_3\") \n",
    "    B8_3 = jsonpath(data, \"$..B8_3\") \n",
    "    B8A_3 = jsonpath(data, \"$..B8A_3\") \n",
    "    B11_3 = jsonpath(data, \"$..B11_3\") \n",
    "    B12_3 = jsonpath(data, \"$..B12_3\") \n",
    "\n",
    "\n",
    "    # In[5]:\n",
    "\n",
    "\n",
    "    number_samples = np.size(B8,0)\n",
    "    dataset_spring= np.zeros((number_samples,   kernel,kernel,10), dtype=float)\n",
    "    dataset_summer= np.zeros((number_samples,   kernel,kernel,10), dtype=float)\n",
    "    dataset_autumn= np.zeros((number_samples,   kernel,kernel,10), dtype=float)\n",
    "    dataset_winter= np.zeros((number_samples,   kernel,kernel,10), dtype=float)\n",
    "    dataset= np.zeros((number_samples,   kernel,kernel,bands), dtype=float)\n",
    "    for i in range(0,number_samples-1):\n",
    "        dataset_spring[i]=np.dstack((np.array(B2[i]),np.array(B3[i]),np.array(B4[i]),np.array(B5[i]),np.array(B6[i]),np.array(B7[i]),np.array(B8[i]),np.array(B8A[i]),np.array(B11[i]),np.array(B12[i])))\n",
    "        dataset_summer[i]=np.dstack((np.array(B2_1[i]),np.array(B3_1[i]),np.array(B4_1[i]),np.array(B5_1[i]),np.array(B6_1[i]),np.array(B7_1[i]),np.array(B8_1[i]),np.array(B8A_1[i]),np.array(B11_1[i]),np.array(B12_1[i])))\n",
    "        dataset_autumn[i]=np.dstack((np.array(B2_2[i]),np.array(B3_2[i]),np.array(B4_2[i]),np.array(B5_2[i]),np.array(B6_2[i]),np.array(B7_2[i]),np.array(B8_2[i]),np.array(B8A_2[i]),np.array(B11_2[i]),np.array(B12_2[i])))\n",
    "        dataset_winter[i]=np.dstack((np.array(B2_3[i]),np.array(B3_3[i]),np.array(B4_3[i]),np.array(B5_3[i]),np.array(B6_3[i]),np.array(B7_3[i]),np.array(B8_3[i]),np.array(B8A_3[i]),np.array(B11_3[i]),np.array(B12_3[i])))\n",
    "        dataset[i]=np.dstack((np.array(dataset_spring[i]),np.array(dataset_summer[i]),np.array(dataset_autumn[i]),np.array(dataset_winter[i])))\n",
    "    print(np.array(dataset).shape)\n",
    "        \n",
    "\n",
    "\n",
    "    # In[6]:\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # In[8]:\n",
    "\n",
    "\n",
    "    ########### define the result train/valid file #############\n",
    "    ### Here the tiles are then saved into numpy arraies\n",
    "    # training samples\n",
    "    t_root = root + tree_type + \"_samples.npy\"\n",
    "    t_sample = []\n",
    "    num_sam = dataset.shape[0]\n",
    "    for i in range(0,num_sam-1):\n",
    "        result = list(navie_sample(dataset[i], index))\n",
    "        t_sample.append(result)\n",
    "    t_sample_array = np.array(t_sample, dtype=object)\n",
    "    print(t_sample_array.shape)\n",
    "    np.save(t_root, t_sample_array)\n",
    "    index += 1\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "with open(os.path.join(root,'indexes.json'), 'w') as fp:\n",
    "    json.dump(index_tree_type, fp)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
